{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands On 1 - Bonus Track\n",
    "In this part, we will test our Apache Spark skills on the Amazon food dataset (that you can find on `/data/Reviews.csv`). The goal is to find all the pairs of products frequently reviewed together.\n",
    "\n",
    "## Task 1\n",
    "The input Amazon food dataset lists all the reviews per-row (one review per line), and it is comma-separated. In each line, two of the columns represent\n",
    "the user id and product id (third and second columns, respectively). The schema of Reviews.csv is the following:\n",
    "\n",
    "|Id|ProductId|UserId|ProfileName|HelpfulnessNumerator|HelpfulnessDenominator|Score|Time|Summary|Text|\n",
    "|--|---------|------|-----------|--------------------|----------------------|-----|----|-------|----|\n",
    "|  |         |      |           |                    |                      |     |    |       |    |\n",
    "\n",
    "Write a single Spark application that:\n",
    "1. Transposes the original Amazon food dataset, obtaining an RDD of pairs (tuples) of the type:\n",
    "_(UserId, list of the ProductId reviewed by that user)_\n",
    "\n",
    "The returned RDD contains one pair/tuple for each user, which contains the `user_id` and the complete list of (distinct) products reviewed by that user. If user `user_id` reviewed more times the same product, that product must occur only one time in the returned list of the `product_ids` reviewed by `user_id`;\n",
    "\n",
    "2. Counts the frequencies of all the pairs of products reviewed together (the frequency of a pair of products is given by the number of users who reviewed both products);\n",
    "\n",
    "3. Stores on the output folder all the pairs of products that appear more than once and their frequencies. The pairs of products must be sorted by decreasing frequency.\n",
    "\n",
    "Inspect the output of your application to search for interesting facts. \n",
    "\n",
    "**Pay attention** that the line starting with `“Id,”` is the header of the file and **must not** be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input and output folders\n",
    "inputPath  = \"data/Reviews.csv\"\n",
    "outputPath = \"out_bonus/\" \n",
    "\n",
    "# Read the content of the input file\n",
    "reviewsRDD = sc.textFile(inputPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard the header\n",
    "reviewsRDDnoHeader = reviewsRDD.filter(lambda line: line.startswith(\"Id,\")==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python function splits the input line and returns a tuple (userId, productId)\n",
    "def extractUserIdProductID(line):\n",
    "    columns = line.split(\",\")\n",
    "    userId= columns[2]\n",
    "    productId= columns[1]\n",
    "    \n",
    "    return (userId,productId)\n",
    "\n",
    "\n",
    "# Generate one pair (UserId, ProductId) from each input line\n",
    "pairUserProductRDD = reviewsRDDnoHeader.map(extractUserIdProductID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate pairs, if any\n",
    "pairUserProductDistinctRDD = pairUserProductRDD.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate one \"transaction\" for each user\n",
    "# (user_id, list of the product_ids reviewed by user_id)\n",
    "UserIDListOfReviewedProductsRDD = pairUserProductDistinctRDD.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are interested only in the value part (the lists of products that have been reviewed together)\n",
    "transactionsRDD = UserIDListOfReviewedProductsRDD.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an input transaction (i.e., a list of products reviewed by the same user), \n",
    "# this Python function returns all the possible pair of products. Each pair of product is associated with\n",
    "# a frequency equal to 1. Hence, this method returns a set of (key, value) pairs, where\n",
    "# - key = pairs of products\n",
    "# - value = 1\n",
    "def extractPairsOfProducts(transaction):\n",
    "\n",
    "    products = list(transaction)\n",
    "\n",
    "    returnedPairs = []\n",
    "    \n",
    "    for product1 in products:\n",
    "        for product2 in products:\n",
    "            if product1<product2:\n",
    "                returnedPairs.append( ((product1, product2), 1) )\n",
    "                \n",
    "    return returnedPairs\n",
    "\n",
    "\n",
    "# Generate an RDD of (key,value) pairs, where\n",
    "# - key = pairs of products\n",
    "# - value = 1\n",
    "\n",
    "# One pair is returned for each combination of products appearing in the same transaction  \n",
    "pairsOfProductsOneRDD = transactionsRDD.flatMap(extractPairsOfProducts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency (i.e., number of occurrences) of each key (= pair of products)\n",
    "pairsFrequenciesRDD = pairsOfProductsOneRDD.reduceByKey(lambda count1, count2: count1 + count2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the pairs that appear more than once and their frequencies.\n",
    "atLeast2PairsFrequenciesRDD = pairsFrequenciesRDD.filter(lambda inputTuple: inputTuple[1]> 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort pairs of products by decreasing frequency\n",
    "atLeast2PairsFrequenciesSortedRDD = atLeast2PairsFrequenciesRDD.sortBy(lambda inputTuple: inputTuple[1], False).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the result in the output folder\n",
    "atLeast2PairsFrequenciesSortedRDD.saveAsTextFile(outputPath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Extend the implemented application in order to write on the standard output the top 10, most frequent, pairs of products and their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pairs of products in atLeast2PairsFrequenciesSortedRDD are already sorted by frequency.\n",
    "# The first 10 pairs are already the top 10 ones\n",
    "topPairsOfProducts = atLeast2PairsFrequenciesSortedRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the selected pairs of products on the standard ouput of the driver\n",
    "for pairOfProducts in topPairsOfProducts:\n",
    "    print(pairOfProducts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Local)",
   "language": "python",
   "name": "pyspark_local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
